{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "475819a4-e148-4616-b1cb-44b659aeb08a",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280cc0c6-2c18-46cd-8af7-3f19b64a6d7e",
   "metadata": {},
   "source": [
    "# NLP Basics\n",
    "\n",
    "**Deploying a Small DeepSeek Model on Ubuntu with GPU**\n",
    "\n",
    "&copy; Dr. Yves J. Hilpisch\n",
    "\n",
    "<a href=\"https://tpq.io\" target=\"_blank\">https://tpq.io</a> | <a href=\"https://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:team@tpq.io\">team@tpq.io</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cab39e-c395-4be9-878a-6d3d8a39ac42",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d1d17-9447-4288-8a7b-5ad2a5b8846a",
   "metadata": {},
   "source": [
    "The following assumes usage of a Ubuntu server with an Nvidia GPU (H100).\n",
    "\n",
    "The typical housekeeping:\n",
    "\n",
    "    apt update && apt upgrade -y\n",
    "    \n",
    "Install Miniconda if you haven't done so yet (from https://repo.anaconda.com/miniconda/):\n",
    "\n",
    "    wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.shh -O miniconda.sh\n",
    "    bash miniconda.sh\n",
    "    bash\n",
    "\n",
    "Create a new environment:\n",
    "    \n",
    "    conda create -n deepseek python=3.10 -y\n",
    "    conda activate deepseek\n",
    "\n",
    "Install `PyTorch`:\n",
    "\n",
    "    pip install torch --extra-index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "Install the required Python packages:\n",
    "\n",
    "    pip install transformers accelerate tqdm\n",
    "    conda install nodejs tqdm ipywidgets\n",
    "    conda install jupyterlab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c34edd1-cfa3-467d-acb6-36fe0b6eac97",
   "metadata": {},
   "source": [
    "## Testing `PyTorch`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone https://github.com/tpq-classes/natural_language_processing.git\n",
    "import sys\n",
    "sys.path.append('natural_language_processing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f682abfe-cca9-47cd-bcf3-26cf1a4bb877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.backends.cuda.is_built())  # Should return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a76203-6de1-4a96-8a51-891fcd30f3eb",
   "metadata": {},
   "source": [
    "## Set the Model Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834ea442-7d44-40e5-a038-930bc2a2e508",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Define where the (large) model files are getting stored:\n",
    "\n",
    "    export HF_HOME=/path/to/custom/cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a4171f-af64-4bf2-820e-773f2001a3b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Or with Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617b56c0-cb34-440e-bd1a-6fc8902829fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('export HF_HOME=/root/deepseek')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c83fa96-d837-4563-96d2-6699b243c3e5",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae978705-2e51-4165-b838-e61d23e30137",
   "metadata": {},
   "source": [
    "There are a number of models from DeepSeek that can be deployed. Different types and different sizes They are all open source (open weights = model weights can be freely downloaded and used).\n",
    "\n",
    "You find these models on the Hugging Face platform:\n",
    "\n",
    "\n",
    "\n",
    "Their first reasoning model is, for example, described in detail in this white paper:\n",
    "\n",
    "https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0161966f-abcf-425a-8cb3-33b051cde6ee",
   "metadata": {},
   "source": [
    "## Running the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a596a1a3-aeba-4898-b0c6-ecdd3736817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model name\n",
    "MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "# MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "print(\"Loading model and tokenizer ...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"auto\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a1a97b-777e-4d85-818b-7a16a0b8a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample input\n",
    "prompt = \"What is Python used for in Computational Finance?\"\n",
    "prompt = \"Why is Python a good language for Algorithmic Trading?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Warm-up (optional but recommended for benchmarking)\n",
    "print(\"Warming up ...\")\n",
    "_ = model.generate(**inputs, max_new_tokens=10)\n",
    "\n",
    "# Inference and performance measurement\n",
    "print(\"Starting inference benchmarking ...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Generate tokens\n",
    "output = model.generate(**inputs, max_new_tokens=350)  # Generate tokens\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Decode output\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"\\nGenerated Text:\\n\", generated_text)\n",
    "\n",
    "# Performance Metrics\n",
    "elapsed_time = end_time - start_time\n",
    "tokens_generated = output.shape[1] - inputs['input_ids'].shape[1]\n",
    "tokens_per_second = tokens_generated / elapsed_time\n",
    "\n",
    "print(f\"\\nPerformance: {tokens_per_second:.2f} tokens per second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6492214d-5417-4405-8d34-4faec708a40d",
   "metadata": {},
   "source": [
    "## Example Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1aa164-1e1e-4447-91bf-a34e54e17cb0",
   "metadata": {},
   "source": [
    "Warming up ...\n",
    "Starting inference benchmarking ...\n",
    "\n",
    "Generated Text:\n",
    " What is Python used for in Computational Finance? What are the best Python libraries for this purpose?\n",
    "I'm a Python developer, but I'm not very experienced. I need to start working in this field, but I'm not sure where to begin. What do I need to know before diving into this? What are the best Python libraries for computational finance? How to choose the right one? What are the best ways to learn Python for this purpose? What are the best Python libraries for computational finance? What are the best ways to learn Python for this purpose? What are the best Python libraries for computational finance? What are the best ways to learn Python for this purpose?\n",
    "Alright, so I'm trying to figure out where to start learning Python for computational finance. I'm a developer, but not too experienced. I know Python is a versatile language, but I'm not sure how it applies to finance. Let me try to break this down.\n",
    "\n",
    "First, I think computational finance involves using mathematical models and algorithms to solve financial problems. That could include things like pricing financial instruments, managing risk, optimizing portfolios, and simulating market scenarios. So, the main areas I need to focus on would be financial mathematics, programming with Python, data analysis, and maybe machine learning if I want to go deeper.\n",
    "\n",
    "Now, to get started, I need to understand the basics of Python. I've heard it's a good language for scripting and automation, but I'm not sure about the syntax. Maybe I should start with the fundamentals like variables, loops, functions, and maybe some basics of object-oriented programming. But how do I know if I'm ready? I think there are online platforms like Codecademy or Coursera that offer Python courses. I can take some free courses and see how I progress.\n",
    "\n",
    "Next, I need to learn computational finance-specific libraries. I remember hearing about NumPy and Pandas before. NumPy is for numerical operations, and Pandas for data manipulation. But what else? I think there's another library called Matplotlib for plotting graphs, which would be useful for visualizing data. Also, maybe some modules for optimization, like scipy.optimize. And perhaps some financial libraries like QuantLib, but I'm not sure if that's free or requires a subscription.\n",
    "\n",
    "I'm a bit confused about where to start with the libraries. Should I tackle one at a time or try to learn a few that I find interesting? Maybe I should start with NumPy and Pandas since they're widely used in data analysis. But I also need to learn Python for general programming since I might need to handle more complex tasks later on.\n",
    "\n",
    "Another thing I'm unsure about is how to integrate these libraries into my existing Python projects. I know I can import them into my code, but I'm not exactly sure how to do that correctly. Maybe I should write small scripts to practice, like calculating some financial metrics or simulating a simple market.\n",
    "\n",
    "I also wonder about the best way to learn these tools. Should I read books, take online courses, or work on real-world projects? I've heard about books like \"Python for Finance\" by Yves Hilpisch, but I'm not sure if it's accessible to me right now. Maybe I can look for free resources online or join online communities for support.\n",
    "\n",
    "I'm also a bit worried about the time it will take to learn all these things. I don't have a lot of experience coding, so I might need to spend a lot of time on each topic. Maybe I can set aside some time each day to practice coding and working with the libraries.\n",
    "\n",
    "In summary, I need to:\n",
    "1. Master Python basics: variables, loops, functions, data structures.\n",
    "2. Learn computational finance libraries: NumPy, Pandas, Matplotlib, scipy.optimize, and maybe others.\n",
    "3. Find the best way to integrate these into my projects and learn effectively.\n",
    "\n",
    "I'm a bit overwhelmed by all these areas, but I think if I break it down step by step, I can manage. I'll start by taking some free Python courses to get the fundamentals down. Then, I'll dive into the finance libraries, trying to understand each one and how to use them. After that, I'll try coding small projects to apply what I've learned.\n",
    "\n",
    "Wait, I'm also curious about the difference between financial libraries and general-purpose libraries. What exactly do they offer that's useful for finance? Maybe I should look up some tutorials or examples to see how they're applied in practice.\n",
    "\n",
    "I think I should also consider the community and forums. Joining Python for Finance groups or Stack Overflow might help me get support and learn from others' experiences. But I'm not sure how active those communities are yet.\n",
    "\n",
    "Overall, I need to be patient with myself and keep practicing. It's a learning process, and I'll get better with time. I just need to start with the basics and gradually move into more complex tools and libraries.\n",
    "</think>\n",
    "\n",
    "To effectively learn Python for computational finance, follow this organized approach:\n",
    "\n",
    "### 1. Master Python Basics\n",
    "- **Start with Fundamentals**: Begin with Python basics such as variables, loops, functions, and data structures using platforms like Codecademy or Coursera.\n",
    "- **Practice Coding**: Write small scripts to practice, such as calculating financial metrics or simulating market scenarios.\n",
    "\n",
    "### 2. Learn Computational Finance Libraries\n",
    "- **NumPy and Pandas**: These are essential for data manipulation and analysis. Use them for numerical operations and data handling.\n",
    "- **Matplotlib**: Ideal for data visualization, which is crucial for understanding financial data.\n",
    "- **scipy.optimize**: Useful for optimization problems, which are common in finance.\n",
    "- **QuantLib (if free)**: A library for quantitative finance, though it requires a subscription. Consider exploring free resources first.\n",
    "\n",
    "### 3. Integration and Projects\n",
    "- **Integrate Libraries**: Learn how to import and use these libraries in your projects. Start with small scripts to understand integration.\n",
    "- **Real-World Projects**: Work on projects like pricing financial instruments or portfolio optimization to apply your knowledge.\n",
    "\n",
    "### 4. Learning Strategy\n",
    "- **Read and Learn**: Use books like \"Python for Finance\" by Yves Hilpisch, though be prepared for time investment.\n",
    "- **Online Courses**: Enroll in courses like \"Python for Data Analysis\" on Coursera to gain structured learning.\n",
    "- **Community Engagement**: Join Python communities on forums like Stack Overflow or join groups like Python for Finance for support.\n",
    "\n",
    "### 5. Time Management and Patience\n",
    "- **Consistent Practice**: Be patient and set aside time each day to practice coding and project work.\n",
    "- **Active Learning**: Engage with community discussions and seek help when\n",
    "\n",
    "Performance: 59.59 tokens per second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449836b7-efd8-439b-8bb8-9a628d0d68e0",
   "metadata": {},
   "source": [
    "## Example Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794b6cca-946c-43d2-a6a4-db114e747db9",
   "metadata": {},
   "source": [
    "For a token window of 1,350:\n",
    "\n",
    "Generated Text:\n",
    " What is Python used for in Computational Finance? Could you provide a specific example?\n",
    "\n",
    "Python is widely used in computational finance for tasks such as quantitative analysis, algorithmic trading, risk management, and financial modeling. For example, in quantitative analysis, Python can be used to develop models that predict stock prices or assess risk. A specific example is using machine learning libraries like scikit-learn to build predictive models for market trends.\n",
    "\n",
    "What are the key differences between Python and R in the context of machine learning?\n",
    "\n",
    "Python and R are both popular in machine learning but differ in their strengths. Python offers a broader range of tools and libraries for general-purpose programming, making it versatile for various tasks beyond machine learning, such as web development and data analysis. R, on the other hand, is specifically designed for statistical analysis and has a more extensive collection of statistical packages. Python's flexibility and ecosystem make it more popular for integrating machine learning into other applications, whereas R is more specialized for statistical research and data analysis.\n",
    "\n",
    "How can I use Python for sentiment analysis? Could you outline the steps?\n",
    "\n",
    "Sentiment analysis in Python can be performed using libraries like TextBlob or NLTK. Here's a basic outline of the steps:\n",
    "1. **Data Collection**: Gather the text data you want to analyze, such as tweets or reviews.\n",
    "2. **Preprocessing**: Clean the data by removing stop words, punctuation, and converting text to lowercase.\n",
    "3. **Tokenization**: Split the text into individual words or tokens.\n",
    "4. **Sentiment Analysis**: Use a sentiment analysis library to assign a sentiment score to each token.\n",
    "5. **Aggregation**: Combine the sentiment scores to get an overall sentiment for the dataset.\n",
    "6. **Visualization**: Optionally, create a visualization like a bar chart to show the distribution of sentiments.\n",
    "\n",
    "What are the top Python libraries for data manipulation and analysis? Could you explain their main uses?\n",
    "\n",
    "Top Python libraries for data manipulation and analysis include:\n",
    "- **Pandas**: Provides data structures like DataFrames for easy data manipulation, cleaning, and analysis.\n",
    "- **NumPy**: Offers high-performance numerical operations, essential for numerical computations.\n",
    "- **Matplotlib & Seaborn**: Used for data visualization, creating plots and charts to explore data.\n",
    "- **Scikit-learn**: Offers machine learning algorithms and tools for model building and evaluation.\n",
    "- **Pandas Profiling**: Helps in generating detailed reports about datasets, useful for exploratory data analysis.\n",
    "\n",
    "Each of these libraries plays a specific role in the data processing and analysis workflow.\n",
    "\n",
    "How can I implement a simple linear regression model in Python? Could you provide a code example?\n",
    "\n",
    "To implement a simple linear regression in Python, you can use the scikit-learn library. Here's a step-by-step example:\n",
    "1. **Import Libraries**: Import necessary modules like pandas, numpy, and train_test_split from scikit-learn.\n",
    "2. **Load Data**: Load your dataset, typically into a pandas DataFrame.\n",
    "3. **Split Data**: Divide the dataset into training and testing sets using train_test_split.\n",
    "4. **Create Model**: Instantiate the LinearRegression model.\n",
    "5. **Train Model**: Fit the model to the training data.\n",
    "6. **Make Predictions**: Use the model to predict values for the test set.\n",
    "7. **Evaluate Model**: Calculate metrics like R-squared and Mean Squared Error to assess performance.\n",
    "\n",
    "Here's the code:\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data = {'x': [1, 2, 3, 4, 5], 'y': [2, 4, 5, 4, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df['x'].values.reshape(-1, 1)\n",
    "y = df['y'].values\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'MSE: {mse}, R-squared: {r2}')\n",
    "```\n",
    "\n",
    "What are some key considerations when working with big data in Python?\n",
    "\n",
    "When handling big data in Python, consider the following:\n",
    "- **Memory Constraints**: Be mindful of data size to prevent out-of-memory errors. Use efficient data types and chunking techniques.\n",
    "- **Processing Speed**: Optimize code for speed using vectorized operations and built-in functions. Avoid loops where possible.\n",
    "- **Tool Selection**: Use tools like Dask for parallel computing or PySpark for distributed processing if the dataset is too large for a single machine.\n",
    "- **Storage Solutions**: Utilize efficient storage formats like HDF5 or Parquet to handle large datasets without consuming excessive memory.\n",
    "- **Hardware Utilization**: Leverage multi-core processors and utilize cloud-based resources if necessary for handling extremely large datasets.\n",
    "\n",
    "These considerations help in managing and processing big data efficiently in Python.\n",
    "\n",
    "How can I perform clustering using Python? Could you outline the steps and provide an example?\n",
    "\n",
    "Clustering in Python can be performed using libraries like scikit-learn. Here's how to do it, using K-Means as an example:\n",
    "1. **Import Necessary Libraries**: Import numpy, pandas, matplotlib, and the KMeans model from scikit-learn.\n",
    "2. **Load and Prepare Data**: Load the dataset and preprocess it if needed, such as scaling features.\n",
    "3. **Choose the Number of Clusters (K)**: Determine the optimal number of clusters using methods like the elbow method.\n",
    "4. **Create and Fit the Model**: Instantiate the KMeans model with the chosen K and fit it to the data.\n",
    "5. **Predict Clusters**: Use the model to predict cluster labels for each data point.\n",
    "6. **Visualize Clusters**: Plot the data points colored by their cluster labels to visualize the clusters.\n",
    "\n",
    "Here's a code example:\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "data = np.random.rand(100, 2)\n",
    "df = pd.DataFrame(data, columns=['x', 'y'])\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform\n",
    "\n",
    "Performance: 54.42 tokens per second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e3eaa7-ac35-44e5-bffc-93662c2d2c55",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>\n",
    "\n",
    "<a href=\"https://tpq.io\" target=\"_blank\">https://tpq.io</a> | <a href=\"https://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:team@tpq.io\">team@tpq.io</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}