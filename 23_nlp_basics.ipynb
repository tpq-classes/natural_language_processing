{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "475819a4-e148-4616-b1cb-44b659aeb08a",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280cc0c6-2c18-46cd-8af7-3f19b64a6d7e",
   "metadata": {},
   "source": [
    "# NLP Basics\n",
    "\n",
    "**Transformers**\n",
    "\n",
    "&copy; Dr. Yves J. Hilpisch\n",
    "\n",
    "<a href=\"https://tpq.io\" target=\"_blank\">https://tpq.io</a> | <a href=\"https://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:team@tpq.io\">team@tpq.io</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9023d91-c34d-44f2-b9e2-8bccd757fc2d",
   "metadata": {},
   "source": [
    "_Code primarily from ChatGPT_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120dab1b-8064-4b44-ac3a-4e74c2facae8",
   "metadata": {},
   "source": [
    "## `transformers` Package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fba79f-a301-46d3-aa2d-15a945f3c6dc",
   "metadata": {},
   "source": [
    "_From ChatGPT_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd2dbc2-54c0-47be-b47e-2b7eca13144b",
   "metadata": {},
   "source": [
    "There is a Python package called **`transformers`**. Developed by [Hugging Face](https://huggingface.co/), it is one of the most popular libraries for implementing transformer models in Natural Language Processing (NLP). The `transformers` library provides a wide range of pre-trained models and tools that make it easy to integrate state-of-the-art machine learning models into your projects.\n",
    "\n",
    "### Key Features:\n",
    "\n",
    "- **Wide Range of Models:**\n",
    "  - Supports popular transformer architectures like BERT, GPT-2, GPT-3, RoBERTa, T5, DistilBERT, and many others.\n",
    "  - Provides thousands of pre-trained models fine-tuned on various tasks and languages.\n",
    "  \n",
    "- **Framework Compatibility:**\n",
    "  - Works seamlessly with both **PyTorch** and **TensorFlow**, allowing you to choose your preferred deep learning framework.\n",
    "  \n",
    "- **Easy Fine-Tuning:**\n",
    "  - Simplifies the process of fine-tuning pre-trained models on custom datasets for tasks like text classification, named entity recognition, question answering, and more.\n",
    "  \n",
    "- **Extensive Documentation and Community Support:**\n",
    "  - Comes with comprehensive documentation, tutorials, and an active community, making it easier to get started and find solutions to common issues.\n",
    "  \n",
    "- **Pipeline API:**\n",
    "  - Offers a high-level API called `pipeline` that allows you to perform tasks with just a few lines of code.\n",
    "\n",
    "### Installation:\n",
    "\n",
    "You can install the `transformers` package using `pip`:\n",
    "\n",
    "```bash\n",
    "pip install transformers\n",
    "```\n",
    "\n",
    "If you plan to use PyTorch or TensorFlow, make sure they are installed as well.\n",
    "\n",
    "### Basic Usage Example:\n",
    "\n",
    "Here's a simple example of how to use the `transformers` library for text generation using GPT-2:\n",
    "\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the text generation pipeline with a pre-trained GPT-2 model\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Generate text based on a prompt\n",
    "output = generator(\"Once upon a time\", max_length=50, num_return_sequences=1)\n",
    "\n",
    "print(output[0]['generated_text'])\n",
    "```\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- **GitHub Repository:**  \n",
    "  [https://github.com/huggingface/transformers](https://github.com/huggingface/transformers)\n",
    "\n",
    "- **Documentation:**  \n",
    "  [https://huggingface.co/docs/transformers/index](https://huggingface.co/docs/transformers/index)\n",
    "\n",
    "- **Tutorials and Guides:**  \n",
    "  [https://huggingface.co/transformers/quickstart.html](https://huggingface.co/transformers/quickstart.html)\n",
    "\n",
    "### Why Use the `transformers` Library?\n",
    "\n",
    "- **State-of-the-Art Performance:** Easily leverage models that achieve top performance on various NLP benchmarks.\n",
    "- **Time and Resource Efficient:** Save time on training models from scratch by using pre-trained models that can be fine-tuned to your specific needs.\n",
    "- **Versatility:** Applicable to a wide array of tasks including but not limited to text classification, translation, summarization, and question answering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7293a7ee-0004-4b0e-8414-05872dcc7ba6",
   "metadata": {},
   "source": [
    "## Use Cases"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone https://github.com/tpq-classes/natural_language_processing.git\n",
    "import sys\n",
    "sys.path.append('natural_language_processing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ad6e18-015d-48a9-980f-6d954ad5cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install tf-keras\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c19221-e9aa-4479-afc1-fdaa7d2d9db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import transformers\n",
    "tf.__version__, transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff0894f-2cf4-4239-9dde-4655f7041b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from transformers import logging as transformers_logging\n",
    "\n",
    "# Set the logging level to ERROR to suppress INFO and WARNING messages\n",
    "transformers_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83362a76-0576-46ac-ab0e-805fe9ea1f85",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f7e866-20de-4e94-b2af-b140c23d2e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the sentiment analysis pipeline\n",
    "sentiment_analyzer = pipeline('sentiment-analysis')\n",
    "\n",
    "# Analyze sentiment\n",
    "result = sentiment_analyzer(\"I love using the transformers library!\")[0]\n",
    "\n",
    "print(f\"Label: {result['label']}, Score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cede17-259a-453a-afbf-338ef3d1902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268b1029-96a7-44eb-80fc-c42b3e35846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentiment\n",
    "result = sentiment_analyzer(\"I only had issues with other packages!\")[0]\n",
    "\n",
    "print(f\"Label: {result['label']}, Score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4d3551-2ee2-4cc6-a4a8-7d95c9d54cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentiment\n",
    "result = sentiment_analyzer(\"I work with multiple such packages.\")[0]\n",
    "\n",
    "print(f\"Label: {result['label']}, Score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d75c06-790d-4974-98af-5c7277866a99",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a9235d-d005-49bd-aeaa-93c71641f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the NER pipeline\n",
    "ner_tagger = pipeline('ner', grouped_entities=True)\n",
    "\n",
    "# Perform NER\n",
    "text = \"Barack Obama was born in Hawaii.\"\n",
    "entities = ner_tagger(text)\n",
    "\n",
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['entity_group']}, Word: {entity['word']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d6bd7b-b4e5-42f4-97be-a273422f64c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5986f86b-2f16-473d-afa6-17bec17fac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform NER\n",
    "text = \"Olaf Scholz is chancelor of Germany.\"\n",
    "entities = ner_tagger(text)\n",
    "\n",
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['entity_group']}, Word: {entity['word']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27148c48-5567-4f2b-b497-c59650939638",
   "metadata": {},
   "source": [
    "### Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa809497-4cf7-449a-be08-a5837ff0886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the question-answering pipeline\n",
    "qa_pipeline = pipeline('question-answering')\n",
    "\n",
    "# Define context and question\n",
    "context = \"Transformers are models that process words in relation to all other words in a sentence.\"\n",
    "question = \"What are transformers?\"\n",
    "\n",
    "# Get the answer\n",
    "answer = qa_pipeline(question=question, context=context)\n",
    "\n",
    "print(f\"Answer: {answer['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a505e-72fb-44fc-8e2e-4d6023535260",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('article.txt', 'r') as f:\n",
    "    context = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa519ad-c9d4-4061-ac75-2fc1092e49ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba145ae-3dd0-4d14-8415-33827e9ade9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How much capital did OpenAI raise?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14beade0-cb47-4e95-b371-962684bd3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the answer\n",
    "answer = qa_pipeline(question=question, context=context)\n",
    "\n",
    "print(f\"Answer: {answer['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149bc59b-d295-48af-ac72-f8ea721ffcde",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4b30c-cbed-4291-b2a0-8a6566c2b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the text generation pipeline\n",
    "text_generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Generate text\n",
    "prompt = \"Once upon a time\"\n",
    "generated_text = text_generator(prompt, max_length=30, num_return_sequences=1)\n",
    "\n",
    "print(generated_text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da70ce-0727-4927-a3ba-b1481e62770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(4):\n",
    "    generated_text = text_generator(prompt, max_length=30, num_return_sequences=1)\n",
    "    print(generated_text[0]['generated_text'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b60cd1-a3b0-4588-8b42-ef9b09590ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"In the near future, AI\"\n",
    "for _ in range(4):\n",
    "    generated_text = text_generator(prompt, max_length=30, num_return_sequences=1)\n",
    "    print(generated_text[0]['generated_text'], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caee256-23c2-4238-8011-7a470fbe6016",
   "metadata": {},
   "source": [
    "### Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cc8427-db40-4937-921d-fc9b9a5f8874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab2fdec-b105-4e2d-93c2-ed14332e0cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the summarization pipeline\n",
    "summarizer = pipeline('summarization')\n",
    "\n",
    "# Short text to summarize\n",
    "text = \"\"\"\n",
    "The transformers library provides state-of-the-art machine learning models for natural language processing.\n",
    "It allows developers to leverage pre-trained models for tasks such as text classification,\n",
    "question answering, and language translation, saving time and computational resources.\n",
    "\"\"\"\n",
    "\n",
    "# Summarize text\n",
    "summary = summarizer(text, max_length=30, min_length=15, do_sample=False)\n",
    "\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ecb22-5885-4863-9da2-ad9da44038cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarizer(context, max_length=50, min_length=15, do_sample=False)\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f8b1b-3537-490e-8cd5-3fef68c66192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0627b2f3-dea3-487d-a16f-93755cf788e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('https://hilpisch.com/walden.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82a07f-f9fd-4120-bcff-cc3f54dafdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db61f8-98a8-450f-b08c-52f8163ca1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarizer(text[2000:5000], max_length=100,\n",
    "                     min_length=25, do_sample=False)\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a841f5-0dbe-48d3-85a7-063ea8c5b5d4",
   "metadata": {},
   "source": [
    "### Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a856f3dc-c996-4577-b6ce-00b7497644f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the translation pipeline\n",
    "translator = pipeline('translation_en_to_de', framework='tf')\n",
    "\n",
    "# Text to translate\n",
    "text = \"Transformers are revolutionizing natural language processing.\"\n",
    "\n",
    "# Translate text\n",
    "translation = translator(text, max_length=40)\n",
    "\n",
    "print(translation[0]['translation_text'])\n",
    "# incorrect output (in terms of meaning):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef2d2ca-5860-4d93-b0e2-fe97a803956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the translation pipeline\n",
    "translator = pipeline('translation_en_to_fr', framework='tf')\n",
    "\n",
    "# Text to translate\n",
    "text = \"Transformers are revolutionizing natural language processing.\"\n",
    "\n",
    "# Translate text\n",
    "translation = translator(text, max_length=40)\n",
    "\n",
    "print(translation[0]['translation_text'])\n",
    "# good output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bdd4b0-ca46-4595-a75c-4d33a3eeb55e",
   "metadata": {},
   "source": [
    "### Fill-Mask (Cloze Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95e9ddf-e807-403a-a0b1-63c0f8d6572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the fill-mask pipeline\n",
    "unmasker = pipeline('fill-mask')\n",
    "\n",
    "# Text with a masked word\n",
    "text = \"Transformers are the <mask> of modern NLP models.\"\n",
    "\n",
    "# Predict the masked word\n",
    "predictions = unmasker(text)\n",
    "\n",
    "for prediction in predictions:\n",
    "    print(f\"Prediction: {prediction['token_str']}, Score: {round(prediction['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ac6f4-9403-4194-b6f7-f25499673658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text with a masked word\n",
    "text = \"NLP is a <mask> technique in finance.\"\n",
    "\n",
    "# Predict the masked word\n",
    "predictions = unmasker(text)\n",
    "\n",
    "for prediction in predictions:\n",
    "    print(f\"Prediction: {prediction['token_str']}, Score: {round(prediction['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8474cd88-7571-4a34-b88a-46088964eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text with a masked word\n",
    "text = \"NLP is an <mask> technique in finance.\"\n",
    "\n",
    "# Predict the masked word\n",
    "predictions = unmasker(text)\n",
    "\n",
    "for prediction in predictions:\n",
    "    print(f\"Prediction: {prediction['token_str']}, Score: {round(prediction['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e3eaa7-ac35-44e5-bffc-93662c2d2c55",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>\n",
    "\n",
    "<a href=\"https://tpq.io\" target=\"_blank\">https://tpq.io</a> | <a href=\"https://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:team@tpq.io\">team@tpq.io</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}