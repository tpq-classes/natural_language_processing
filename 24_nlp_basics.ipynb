{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "475819a4-e148-4616-b1cb-44b659aeb08a",
      "metadata": {
        "id": "475819a4-e148-4616-b1cb-44b659aeb08a"
      },
      "source": [
        "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "280cc0c6-2c18-46cd-8af7-3f19b64a6d7e",
      "metadata": {
        "id": "280cc0c6-2c18-46cd-8af7-3f19b64a6d7e"
      },
      "source": [
        "# NLP Basics\n",
        "\n",
        "**Transformers**\n",
        "\n",
        "&copy; Dr. Yves J. Hilpisch\n",
        "\n",
        "<a href=\"https://tpq.io\" target=\"_blank\">https://tpq.io</a> | <a href=\"https://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:team@tpq.io\">team@tpq.io</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9023d91-c34d-44f2-b9e2-8bccd757fc2d",
      "metadata": {
        "id": "d9023d91-c34d-44f2-b9e2-8bccd757fc2d"
      },
      "source": [
        "_Code primarily from ChatGPT_."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "120dab1b-8064-4b44-ac3a-4e74c2facae8",
      "metadata": {
        "id": "120dab1b-8064-4b44-ac3a-4e74c2facae8"
      },
      "source": [
        "## `transformers` Package"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98fba79f-a301-46d3-aa2d-15a945f3c6dc",
      "metadata": {
        "id": "98fba79f-a301-46d3-aa2d-15a945f3c6dc"
      },
      "source": [
        "_From ChatGPT_."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7293a7ee-0004-4b0e-8414-05872dcc7ba6",
      "metadata": {
        "id": "7293a7ee-0004-4b0e-8414-05872dcc7ba6"
      },
      "source": [
        "## Use Cases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snytEVHTFDrE"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "!git clone https://github.com/tpq-classes/natural_language_processing.git\n",
        "import sys\n",
        "sys.path.append('natural_language_processing')\n"
      ],
      "id": "snytEVHTFDrE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17ad6e18-015d-48a9-980f-6d954ad5cb13",
      "metadata": {
        "id": "17ad6e18-015d-48a9-980f-6d954ad5cb13"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow\n",
        "# !pip install tf-keras\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68c19221-e9aa-4479-afc1-fdaa7d2d9db5",
      "metadata": {
        "id": "68c19221-e9aa-4479-afc1-fdaa7d2d9db5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import transformers\n",
        "tf.__version__, transformers.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ff0894f-2cf4-4239-9dde-4655f7041b64",
      "metadata": {
        "id": "4ff0894f-2cf4-4239-9dde-4655f7041b64"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "from transformers import logging as transformers_logging\n",
        "\n",
        "# Set the logging level to ERROR to suppress INFO and WARNING messages\n",
        "transformers_logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ce690b5-6799-45b6-8038-3c56c890ad09",
      "metadata": {
        "id": "2ce690b5-6799-45b6-8038-3c56c890ad09"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84c2f7e7-b8ed-4c10-b556-0b4b7654b911",
      "metadata": {
        "id": "84c2f7e7-b8ed-4c10-b556-0b4b7654b911"
      },
      "source": [
        "### Machine Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83c216fc-e17b-404f-a9f7-bc417645e653",
      "metadata": {
        "id": "83c216fc-e17b-404f-a9f7-bc417645e653"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the translation pipeline\n",
        "translator = pipeline('translation_en_to_de')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0530a97-b499-4485-86ea-50474d3a7705",
      "metadata": {
        "id": "d0530a97-b499-4485-86ea-50474d3a7705"
      },
      "outputs": [],
      "source": [
        "# Text to translate\n",
        "text = \"Transformers are revolutionizing natural language processing.\"\n",
        "\n",
        "# Translate text\n",
        "translation = translator(text, max_length=40)\n",
        "\n",
        "print(translation[0]['translation_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be96cf1b-f09e-411d-8c31-52b2660d5307",
      "metadata": {
        "id": "be96cf1b-f09e-411d-8c31-52b2660d5307"
      },
      "outputs": [],
      "source": [
        "news = \"\"\"Group Chief Executive Masayoshi Son reiterated his bullish forecasts for artificial intelligence\n",
        "in a speech Thursday that stressed advances made by OpenAI.\n",
        "\n",
        "OpenAI raised $6.6 billion in a recent round of new funding that included a $500 million\n",
        "investment by SoftBank, according to a person familiar with the matter.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73049e9a-6789-4de8-a70e-79a8c334d85b",
      "metadata": {
        "id": "73049e9a-6789-4de8-a70e-79a8c334d85b"
      },
      "outputs": [],
      "source": [
        "# Translate text\n",
        "translation = translator(news, max_length=70)\n",
        "\n",
        "print(translation[0]['translation_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "645dd27f-66d4-4103-87e5-05ee9ac5e80f",
      "metadata": {
        "id": "645dd27f-66d4-4103-87e5-05ee9ac5e80f"
      },
      "source": [
        "### Language Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a95e9ddf-e807-403a-a0b1-63c0f8d6572a",
      "metadata": {
        "id": "a95e9ddf-e807-403a-a0b1-63c0f8d6572a"
      },
      "outputs": [],
      "source": [
        "# Initialize the zero-shot classification pipeline\n",
        "classifier = pipeline('zero-shot-classification')\n",
        "\n",
        "# Text in an unknown language\n",
        "text = \"Je suis tr√®s heureux aujourd'hui.\"\n",
        "# text = \"I am quite happy today.\"\n",
        "# text = \"Heute geht es mir wirklich gut.\"\n",
        "\n",
        "# Candidate labels (languages)\n",
        "labels = ['English', 'French', 'German', 'Spanish']\n",
        "\n",
        "# Classify language\n",
        "result = classifier(text, candidate_labels=labels)\n",
        "\n",
        "print(\"Detected Language:\", result['labels'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83362a76-0576-46ac-ab0e-805fe9ea1f85",
      "metadata": {
        "id": "83362a76-0576-46ac-ab0e-805fe9ea1f85"
      },
      "source": [
        "### Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78ff93b6-98a3-45bc-9ccf-8148d1c10dbc",
      "metadata": {
        "id": "78ff93b6-98a3-45bc-9ccf-8148d1c10dbc"
      },
      "outputs": [],
      "source": [
        "# Initialize the feature extraction pipeline\n",
        "feature_extractor = pipeline('feature-extraction')\n",
        "\n",
        "# Text to extract features from\n",
        "text = \"Transformers provide embeddings for NLP tasks.\"\n",
        "\n",
        "# Extract features\n",
        "features = feature_extractor(text)\n",
        "\n",
        "print(f\"Feature vector length: {len(features[0])} tokens\")\n",
        "print(f\"Embedding size per token: {len(features[0][0])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dabb946d-262a-4397-9d71-a7c206f24e25",
      "metadata": {
        "id": "dabb946d-262a-4397-9d71-a7c206f24e25"
      },
      "outputs": [],
      "source": [
        "# Extract features\n",
        "features = feature_extractor(news)\n",
        "\n",
        "print(f\"Feature vector length: {len(features[0])} tokens\")\n",
        "print(f\"Embedding size per token: {len(features[0][0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11118cc2-c6a2-472f-8239-0453911b4202",
      "metadata": {
        "id": "11118cc2-c6a2-472f-8239-0453911b4202"
      },
      "source": [
        "### Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ab2fdec-b105-4e2d-93c2-ed14332e0cec",
      "metadata": {
        "id": "1ab2fdec-b105-4e2d-93c2-ed14332e0cec"
      },
      "outputs": [],
      "source": [
        "# Initialize the text classification pipeline\n",
        "classifier = pipeline('text-classification')\n",
        "\n",
        "# Text to classify\n",
        "text = \"The stock market crashed due to unforeseen circumstances.\"\n",
        "# text = \"Today was a good day for stock market investors.\"\n",
        "\n",
        "# Classify text\n",
        "result = classifier(text)[0]\n",
        "\n",
        "print(f\"Label: {result['label']}, Score: {round(result['score'], 4)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15d75c06-790d-4974-98af-5c7277866a99",
      "metadata": {
        "id": "15d75c06-790d-4974-98af-5c7277866a99"
      },
      "source": [
        "### Zero-Short Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8a9235d-d005-49bd-aeaa-93c71641f389",
      "metadata": {
        "id": "a8a9235d-d005-49bd-aeaa-93c71641f389"
      },
      "outputs": [],
      "source": [
        "# Initialize the zero-shot classification pipeline\n",
        "classifier = pipeline('zero-shot-classification')\n",
        "\n",
        "# Text to classify\n",
        "text = \"I love to program in Python and build machine learning models.\"\n",
        "# text = \"Bayern Munich is the record holder for German Bundesliga championships.\"\n",
        "\n",
        "# Candidate labels\n",
        "labels = ['education', 'politics', 'technology', 'sports', 'programming']\n",
        "\n",
        "# Classify text\n",
        "result = classifier(text, candidate_labels=labels)\n",
        "\n",
        "print(\"Sequence:\", result['sequence'])\n",
        "print(\"Labels and scores:\")\n",
        "for label, score in zip(result['labels'], result['scores']):\n",
        "    print(f\"{label}: {round(score, 4)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "id": "kadQw-OSPzz9"
      },
      "id": "kadQw-OSPzz9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "149bc59b-d295-48af-ac72-f8ea721ffcde",
      "metadata": {
        "id": "149bc59b-d295-48af-ac72-f8ea721ffcde"
      },
      "source": [
        "### Sentence Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9b4b30c-cbed-4291-b2a0-8a6566c2b9c5",
      "metadata": {
        "id": "f9b4b30c-cbed-4291-b2a0-8a6566c2b9c5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "model_name = 'sentence-transformers/paraphrase-MiniLM-L6-v2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# Explicitly set from_pt=True to ensure proper loading of PyTorch weights for TensorFlow\n",
        "model = TFAutoModel.from_pretrained(model_name, from_pt=True)\n",
        "\n",
        "# Sentences to compare\n",
        "sentence1 = \"A man is playing a guitar.\"\n",
        "# sentence2 = \"Several men are playing guitars.\"\n",
        "sentence2 = \"Someone is strumming a musical instrument.\"\n",
        "# sentence2 = \"A man is playing a piano.\"\n",
        "\n",
        "# Tokenize sentences\n",
        "encoded1 = tokenizer(sentence1, return_tensors='tf')\n",
        "encoded2 = tokenizer(sentence2, return_tensors='tf')\n",
        "\n",
        "# Compute embeddings\n",
        "embedding1 = model(**encoded1).last_hidden_state  # Shape: (1, sequence_length, hidden_size)\n",
        "embedding2 = model(**encoded2).last_hidden_state  # Shape: (1, sequence_length, hidden_size)\n",
        "\n",
        "# Mean pooling to get sentence embeddings\n",
        "embedding1 = tf.reduce_mean(embedding1, axis=1)  # Shape: (1, hidden_size)\n",
        "embedding2 = tf.reduce_mean(embedding2, axis=1)  # Shape: (1, hidden_size)\n",
        "\n",
        "# Compute cosine similarity\n",
        "cosine_similarity = tf.keras.losses.cosine_similarity(embedding1, embedding2, axis=1)\n",
        "cosine_similarity = -cosine_similarity  # Convert from loss to similarity score\n",
        "\n",
        "print(f\"Cosine Similarity: {cosine_similarity.numpy()[0]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d3c660d-0708-409a-a4c0-35e014c786b3",
      "metadata": {
        "id": "8d3c660d-0708-409a-a4c0-35e014c786b3"
      },
      "source": [
        "### Emotion Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2727e8f8-82b9-437c-982c-ca287b6ca626",
      "metadata": {
        "id": "2727e8f8-82b9-437c-982c-ca287b6ca626"
      },
      "outputs": [],
      "source": [
        "# Initialize the zero-shot classification pipeline\n",
        "classifier = pipeline('zero-shot-classification')\n",
        "\n",
        "# Text expressing emotion\n",
        "text = \"I can't believe I won the lottery!\"\n",
        "text = \"I am angry at our judicial system.\"\n",
        "text = \"I am afraid of my next mathematics exam.\"\n",
        "\n",
        "# Candidate labels\n",
        "labels = ['joy', 'sadness', 'anger', 'fear', 'surprise']\n",
        "\n",
        "# Classify emotion\n",
        "result = classifier(text, candidate_labels=labels)\n",
        "\n",
        "print(\"Detected Emotion:\", result['labels'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "047116c1-0af3-4b1a-b1a1-11ebf5363577",
      "metadata": {
        "id": "047116c1-0af3-4b1a-b1a1-11ebf5363577"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85e74e40-f08a-46f2-ab8e-9818ae568cb1",
      "metadata": {
        "id": "85e74e40-f08a-46f2-ab8e-9818ae568cb1"
      },
      "source": [
        "### Extractive Q&A From Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c516e1cd-3d38-4a0d-95bb-8ecbc68e2094",
      "metadata": {
        "id": "c516e1cd-3d38-4a0d-95bb-8ecbc68e2094"
      },
      "outputs": [],
      "source": [
        "# Initialize the question-answering pipeline\n",
        "qa_pipeline = pipeline('question-answering')\n",
        "\n",
        "# Load a longer context (could be from a file)\n",
        "context = \"\"\"\n",
        "The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France.\n",
        "It is named after the engineer Gustave Eiffel, whose company designed and built the tower.\n",
        "Constructed from 1887 to 1889 as the entrance to the 1889 World's Fair,\n",
        "it was initially criticized by some of France's leading artists and intellectuals\n",
        "for its design, but it has become a global cultural icon of France and one of the most\n",
        "recognizable structures in the world.\n",
        "\"\"\"\n",
        "\n",
        "# Define a question\n",
        "question = \"Who designed the Eiffel Tower?\"\n",
        "\n",
        "# Get the answer\n",
        "answer = qa_pipeline(question=question, context=context)\n",
        "\n",
        "print(f\"Answer: {answer['answer']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b45798f7-7235-42ce-9c9f-cb4383a1060a",
      "metadata": {
        "id": "b45798f7-7235-42ce-9c9f-cb4383a1060a"
      },
      "outputs": [],
      "source": [
        "# Define a question\n",
        "question = \"When was the Eiffel Tower built?\"\n",
        "\n",
        "# Get the answer\n",
        "answer = qa_pipeline(question=question, context=context)\n",
        "\n",
        "print(f\"Answer: {answer['answer']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f2ff538-bf97-498a-bff4-d1fd120a5e2e",
      "metadata": {
        "id": "2f2ff538-bf97-498a-bff4-d1fd120a5e2e"
      },
      "outputs": [],
      "source": [
        "# Define a question\n",
        "question = \"What type of structure is the Eiffel Tower?\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a861873-73d5-46e2-915f-0c46bcb59cdb",
      "metadata": {
        "id": "8a861873-73d5-46e2-915f-0c46bcb59cdb"
      },
      "outputs": [],
      "source": [
        "with open('/content/natural_language_processing/article.txt', 'r') as f:\n",
        "    article = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0370bb71-6b9d-41e1-8652-9ddb95efba8a",
      "metadata": {
        "id": "0370bb71-6b9d-41e1-8652-9ddb95efba8a"
      },
      "outputs": [],
      "source": [
        "article[:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeda1d90-f8d8-4fa6-b1ce-03951b4c669d",
      "metadata": {
        "id": "aeda1d90-f8d8-4fa6-b1ce-03951b4c669d"
      },
      "outputs": [],
      "source": [
        "question = \"How much capital did OpenAI raise?\"\n",
        "# Get the answer\n",
        "answer = qa_pipeline(question=question, context=article)\n",
        "\n",
        "print(f\"Answer: {answer['answer']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20e3eaa7-ac35-44e5-bffc-93662c2d2c55",
      "metadata": {
        "id": "20e3eaa7-ac35-44e5-bffc-93662c2d2c55"
      },
      "source": [
        "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>\n",
        "\n",
        "<a href=\"https://tpq.io\" target=\"_blank\">https://tpq.io</a> | <a href=\"https://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:team@tpq.io\">team@tpq.io</a>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}