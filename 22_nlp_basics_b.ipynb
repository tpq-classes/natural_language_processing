{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "475819a4-e148-4616-b1cb-44b659aeb08a",
      "metadata": {
        "id": "475819a4-e148-4616-b1cb-44b659aeb08a"
      },
      "source": [
        "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "280cc0c6-2c18-46cd-8af7-3f19b64a6d7e",
      "metadata": {
        "id": "280cc0c6-2c18-46cd-8af7-3f19b64a6d7e"
      },
      "source": [
        "# NLP Basics\n",
        "\n",
        "**Transformers**\n",
        "\n",
        "&copy; Dr. Yves J. Hilpisch\n",
        "\n",
        "<a href=\"https://tpq.io\" target=\"_blank\">https://tpq.io</a> | <a href=\"https://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:team@tpq.io\">team@tpq.io</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9023d91-c34d-44f2-b9e2-8bccd757fc2d",
      "metadata": {
        "id": "d9023d91-c34d-44f2-b9e2-8bccd757fc2d"
      },
      "source": [
        "_Code primarily from ChatGPT_."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "120dab1b-8064-4b44-ac3a-4e74c2facae8",
      "metadata": {
        "id": "120dab1b-8064-4b44-ac3a-4e74c2facae8"
      },
      "source": [
        "## Transformer Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSgLPc2tHuRb"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "!git clone https://github.com/tpq-classes/natural_language_processing.git\n",
        "import sys\n",
        "sys.path.append('natural_language_processing')\n"
      ],
      "id": "xSgLPc2tHuRb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c9232ad-a70a-4fec-873b-15ea751c3d0b",
      "metadata": {
        "id": "0c9232ad-a70a-4fec-873b-15ea751c3d0b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d086ac3-ccfa-4285-85d4-997a9ea82f94",
      "metadata": {
        "id": "0d086ac3-ccfa-4285-85d4-997a9ea82f94"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.attention = layers.MultiHeadAttention(num_heads=num_heads,\n",
        "                                                   key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            layers.Dense(ff_dim, activation=\"relu\"),\n",
        "            layers.Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.attention(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a7d3e2d-fa17-45d9-b52b-b922cb897b17",
      "metadata": {
        "id": "2a7d3e2d-fa17-45d9-b52b-b922cb897b17"
      },
      "source": [
        "## Transformer Example (2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e7785f7-ec85-4227-98e7-d10569f13a5e",
      "metadata": {
        "id": "0e7785f7-ec85-4227-98e7-d10569f13a5e"
      },
      "source": [
        "**Text Generation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ef69397-2d1e-4163-87b4-692cda8d0f87",
      "metadata": {
        "id": "3ef69397-2d1e-4163-87b4-692cda8d0f87"
      },
      "outputs": [],
      "source": [
        "# Define the Transformer-based text generation model\n",
        "def create_transformer_model(input_shape, vocab_size, embed_dim, num_heads, ff_dim):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\n",
        "    x = TransformerEncoder(embed_dim, num_heads, ff_dim)(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "950831c0-d386-4651-b2a2-4522eeac9df9",
      "metadata": {
        "id": "950831c0-d386-4651-b2a2-4522eeac9df9"
      },
      "source": [
        "## Transformer Application (2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d300eaa3-3f0c-407b-b3f3-0219bbd3e93a",
      "metadata": {
        "id": "d300eaa3-3f0c-407b-b3f3-0219bbd3e93a"
      },
      "source": [
        "**Text Generation**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31bff230-67a6-4676-8b13-01dd7753e768",
      "metadata": {
        "id": "31bff230-67a6-4676-8b13-01dd7753e768"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82a6140b-b336-4e55-92a2-099d2b0c477e",
      "metadata": {
        "id": "82a6140b-b336-4e55-92a2-099d2b0c477e"
      },
      "outputs": [],
      "source": [
        "# Sample text data for training\n",
        "data = \"\"\"\n",
        "In the beginning there was nothing.\n",
        "The stars formed from dust.\n",
        "Then there were planets, moons, and life.\n",
        "Time passed, and civilizations rose and fell.\n",
        "The universe continues to expand.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "353b82bf-5f0e-492d-9a48-0160678b9bb4",
      "metadata": {
        "id": "353b82bf-5f0e-492d-9a48-0160678b9bb4"
      },
      "outputs": [],
      "source": [
        "with open('/content/natural_language_processing/article.txt', 'r') as f:\n",
        "    data = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b720ab8-85b4-4709-8db2-ea40714bf7c2",
      "metadata": {
        "id": "7b720ab8-85b4-4709-8db2-ea40714bf7c2"
      },
      "outputs": [],
      "source": [
        "# print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ff52d30-7bea-428e-a68d-fa57cb17e4ea",
      "metadata": {
        "id": "1ff52d30-7bea-428e-a68d-fa57cb17e4ea"
      },
      "outputs": [],
      "source": [
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5822f30e-dfc4-4125-b0a6-cb597502c566",
      "metadata": {
        "id": "5822f30e-dfc4-4125-b0a6-cb597502c566"
      },
      "outputs": [],
      "source": [
        "# Convert the text to sequences of integers\n",
        "sequences = tokenizer.texts_to_sequences([data])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7453285b-86f8-4c6c-b204-0707598a2e3d",
      "metadata": {
        "id": "7453285b-86f8-4c6c-b204-0707598a2e3d"
      },
      "outputs": [],
      "source": [
        "# Prepare input-output pairs for training (next word prediction)\n",
        "input_sequences = []\n",
        "output_words = []\n",
        "for i in range(1, len(sequences)):\n",
        "    input_sequences.append(sequences[i-5:i])  # All or x tokens before the current token\n",
        "    output_words.append(sequences[i])      # Current token as the output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a05c9e6f-3fd8-4d20-80cc-dc6937faf333",
      "metadata": {
        "id": "a05c9e6f-3fd8-4d20-80cc-dc6937faf333"
      },
      "outputs": [],
      "source": [
        "# Pad the input sequences to have the same length\n",
        "maxlen = max(len(x) for x in input_sequences)  # Maximum sequence length\n",
        "input_sequences = pad_sequences(input_sequences,\n",
        "                                maxlen=maxlen,\n",
        "                                padding='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3e38496-ea05-4990-8518-5aca159d599b",
      "metadata": {
        "id": "c3e38496-ea05-4990-8518-5aca159d599b"
      },
      "outputs": [],
      "source": [
        "# Convert output words to a NumPy array\n",
        "output_words = np.array(output_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3da2b18-dc72-4abe-94e8-bafb4c252120",
      "metadata": {
        "id": "a3da2b18-dc72-4abe-94e8-bafb4c252120"
      },
      "outputs": [],
      "source": [
        "# Get vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Add 1 for padding token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16bfd0ea-97bb-4a7e-b24c-ab35b11adfa1",
      "metadata": {
        "id": "16bfd0ea-97bb-4a7e-b24c-ab35b11adfa1"
      },
      "outputs": [],
      "source": [
        "# Set parameters for the model\n",
        "embed_dim = 64  # Embedding size for each token\n",
        "num_heads = 4   # Number of attention heads\n",
        "ff_dim = 128    # Hidden layer size in feed-forward network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a50dc970-6676-4718-be10-f06b8bef9770",
      "metadata": {
        "id": "a50dc970-6676-4718-be10-f06b8bef9770"
      },
      "outputs": [],
      "source": [
        "# Create and compile the model\n",
        "model = create_transformer_model(input_shape=(maxlen,),\n",
        "                vocab_size=vocab_size, embed_dim=embed_dim,\n",
        "                num_heads=num_heads, ff_dim=ff_dim)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb147d80-1122-4810-a344-b6f183e10e08",
      "metadata": {
        "id": "eb147d80-1122-4810-a344-b6f183e10e08"
      },
      "outputs": [],
      "source": [
        "# Print the model architecture\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cb3f0a1-6040-45e2-bffa-4e166c5f41f8",
      "metadata": {
        "id": "6cb3f0a1-6040-45e2-bffa-4e166c5f41f8"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Train the model\n",
        "history = model.fit(input_sequences, output_words,\n",
        "                    epochs=300, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d535538c-ae79-4478-86b7-8f17876a0c66",
      "metadata": {
        "id": "d535538c-ae79-4478-86b7-8f17876a0c66"
      },
      "outputs": [],
      "source": [
        "model.evaluate(input_sequences, output_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "939c28e0-a808-4334-99e1-4f741cc3f356",
      "metadata": {
        "id": "939c28e0-a808-4334-99e1-4f741cc3f356"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb2589c2-1e7e-45a1-a70c-8af80ebf29d3",
      "metadata": {
        "id": "cb2589c2-1e7e-45a1-a70c-8af80ebf29d3"
      },
      "outputs": [],
      "source": [
        "# Function to generate text based on a seed input\n",
        "def generate_text(seed_text, num_words, tokenizer, maxlen):\n",
        "    for _ in range(num_words):\n",
        "        # Tokenize and pad the seed text\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=maxlen, padding='pre')\n",
        "\n",
        "        # Predict the next word using the trained model\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        predicted_word_index = np.argmax(predicted_probs, axis=1)[0]\n",
        "\n",
        "        # Convert the predicted index to the word\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_word_index:\n",
        "                seed_text += ' ' + word\n",
        "                break\n",
        "\n",
        "    return seed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "269686a0-45a8-43ee-b254-da5f01c59ca9",
      "metadata": {
        "id": "269686a0-45a8-43ee-b254-da5f01c59ca9"
      },
      "outputs": [],
      "source": [
        "# Example of generating text\n",
        "seed_text = \"son said he believed artificial general\"\n",
        "# seed_text = \"asked the AI program how\"\n",
        "generated_text = generate_text(seed_text, num_words=15,\n",
        "                               tokenizer=tokenizer,\n",
        "                               maxlen=maxlen)\n",
        "\n",
        "print(f\"Generated text: {generated_text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20e3eaa7-ac35-44e5-bffc-93662c2d2c55",
      "metadata": {
        "id": "20e3eaa7-ac35-44e5-bffc-93662c2d2c55"
      },
      "source": [
        "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>\n",
        "\n",
        "<a href=\"https://tpq.io\" target=\"_blank\">https://tpq.io</a> | <a href=\"https://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:team@tpq.io\">team@tpq.io</a>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}